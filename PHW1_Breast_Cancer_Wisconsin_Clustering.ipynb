{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4b1e225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b30d447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of data\n",
      "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
      "0             1000025                5                        1   \n",
      "1             1002945                5                        4   \n",
      "2             1015425                3                        1   \n",
      "3             1016277                6                        8   \n",
      "4             1017023                4                        1   \n",
      "\n",
      "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
      "0                         1                  1                            2   \n",
      "1                         4                  5                            7   \n",
      "2                         1                  1                            2   \n",
      "3                         8                  1                            3   \n",
      "4                         1                  3                            2   \n",
      "\n",
      "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
      "0           1                3                1        1      2  \n",
      "1          10                3                2        1      2  \n",
      "2           2                3                1        1      2  \n",
      "3           4                3                7        1      2  \n",
      "4           1                3                1        1      2  \n",
      "\n",
      "Data shape\n",
      "(699, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "df = pd.read_csv('breast-cancer-wisconsin2.data') # No column name in dataset, read first line as value\n",
    "print(f'First 5 rows of data\\n{df.head()}', end='\\n\\n')\n",
    "print(f'Data shape\\n{df.shape}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5d4befae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation Request:\n",
      "   This breast cancer databases was obtained from the University of Wisconsin\n",
      "   Hospitals, Madison from Dr. William H. Wolberg.  If you publish results\n",
      "   when using this database, then please include this information in your\n",
      "   acknowledgements.  Also, please cite one or more of:\n",
      "\n",
      "   1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear \n",
      "      programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\n",
      "\n",
      "   2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology\", \n",
      "      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, \n",
      "      December 1990, pp 9193-9196.\n",
      "\n",
      "   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition \n",
      "      via linear programming: Theory and application to medical diagnosis\", \n",
      "      in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying\n",
      "      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\n",
      "\n",
      "   4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming \n",
      "      discrimination of two linearly inseparable sets\", Optimization Methods\n",
      "      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).\n",
      "\n",
      "1. Title: Wisconsin Breast Cancer Database (January 8, 1991)\n",
      "\n",
      "2. Sources:\n",
      "   -- Dr. WIlliam H. Wolberg (physician)\n",
      "      University of Wisconsin Hospitals\n",
      "      Madison, Wisconsin\n",
      "      USA\n",
      "   -- Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
      "      Received by David W. Aha (aha@cs.jhu.edu)\n",
      "   -- Date: 15 July 1992\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   Attributes 2 through 10 have been used to represent instances.\n",
      "   Each instance has one of 2 possible classes: benign or malignant.\n",
      "\n",
      "   1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology. In\n",
      "      {\\it Proceedings of the National Academy of Sciences}, {\\it 87},\n",
      "      9193--9196.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Collected classification results: 1 trial only\n",
      "      -- Two pairs of parallel hyperplanes were found to be consistent with\n",
      "         50% of the data\n",
      "         -- Accuracy on remaining 50% of dataset: 93.5%\n",
      "      -- Three pairs of parallel hyperplanes were found to be consistent with\n",
      "         67% of data\n",
      "         -- Accuracy on remaining 33% of dataset: 95.9%\n",
      "\n",
      "   2. Zhang,~J. (1992). Selecting typical instances in instance-based\n",
      "      learning.  In {\\it Proceedings of the Ninth International Machine\n",
      "      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan\n",
      "      Kaufmann.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Applied 4 instance-based learning algorithms \n",
      "      -- Collected classification results averaged over 10 trials\n",
      "      -- Best accuracy result: \n",
      "         -- 1-nearest neighbor: 93.7%\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "      -- Also of interest:\n",
      "         -- Using only typical instances: 92.2% (storing only 23.1 instances)\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
      "   The database therefore reflects this chronological grouping of the data.\n",
      "   This grouping information appears immediately below, having been removed\n",
      "   from the data itself:\n",
      "\n",
      "     Group 1: 367 instances (January 1989)\n",
      "     Group 2:  70 instances (October 1989)\n",
      "     Group 3:  31 instances (February 1990)\n",
      "     Group 4:  17 instances (April 1990)\n",
      "     Group 5:  48 instances (August 1990)\n",
      "     Group 6:  49 instances (Updated January 1991)\n",
      "     Group 7:  31 instances (June 1991)\n",
      "     Group 8:  86 instances (November 1991)\n",
      "     -----------------------------------------\n",
      "     Total:   699 points (as of the donated datbase on 15 July 1992)\n",
      "\n",
      "   Note that the results summarized above in Past Usage refer to a dataset\n",
      "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
      "   originally contained 369 instances; 2 were removed.  The following\n",
      "   statements summarizes changes to the original Group 1's set of data:\n",
      "\n",
      "   #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
      "   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
      "   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
      "   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
      "   #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
      "   #####                  : Changed 0 to 1 in field 8 of following sample:\n",
      "   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
      "\n",
      "5. Number of Instances: 699 (as of 15 July 1992)\n",
      "\n",
      "6. Number of Attributes: 10 plus the class attribute\n",
      "\n",
      "7. Attribute Information: (class attribute has been moved to last column)\n",
      "\n",
      "   #  Attribute                     Domain\n",
      "   -- -----------------------------------------\n",
      "   1. Sample code number            id number\n",
      "   2. Clump Thickness               1 - 10\n",
      "   3. Uniformity of Cell Size       1 - 10\n",
      "   4. Uniformity of Cell Shape      1 - 10\n",
      "   5. Marginal Adhesion             1 - 10\n",
      "   6. Single Epithelial Cell Size   1 - 10\n",
      "   7. Bare Nuclei                   1 - 10\n",
      "   8. Bland Chromatin               1 - 10\n",
      "   9. Normal Nucleoli               1 - 10\n",
      "  10. Mitoses                       1 - 10\n",
      "  11. Class:                        (2 for benign, 4 for malignant)\n",
      "\n",
      "8. Missing attribute values: 16\n",
      "\n",
      "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
      "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
      "\n",
      "9. Class distribution:\n",
      " \n",
      "   Benign: 458 (65.5%)\n",
      "   Malignant: 241 (34.5%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"breast-cancer-wisconsin.names\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "82eea952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                  5                        1                         1   \n",
       "1                  5                        4                         4   \n",
       "2                  3                        1                         1   \n",
       "3                  6                        8                         8   \n",
       "4                  4                        1                         1   \n",
       "..               ...                      ...                       ...   \n",
       "694                3                        1                         1   \n",
       "695                2                        1                         1   \n",
       "696                5                       10                        10   \n",
       "697                4                        8                         6   \n",
       "698                4                        8                         8   \n",
       "\n",
       "     Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  \\\n",
       "0                    1                            2           1   \n",
       "1                    5                            7          10   \n",
       "2                    1                            2           2   \n",
       "3                    1                            3           4   \n",
       "4                    3                            2           1   \n",
       "..                 ...                          ...         ...   \n",
       "694                  1                            3           2   \n",
       "695                  1                            2           1   \n",
       "696                  3                            7           3   \n",
       "697                  4                            3           4   \n",
       "698                  5                            4           5   \n",
       "\n",
       "     Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0                  3                1        1      2  \n",
       "1                  3                2        1      2  \n",
       "2                  3                1        1      2  \n",
       "3                  3                7        1      2  \n",
       "4                  3                1        1      2  \n",
       "..               ...              ...      ...    ...  \n",
       "694                1                1        1      2  \n",
       "695                1                1        1      2  \n",
       "696                8               10        2      4  \n",
       "697               10                6        1      4  \n",
       "698               10                4        1      4  \n",
       "\n",
       "[699 rows x 10 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering\n",
    "df = df.drop([\"Sample code number\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d22d1d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: Bare Nuclei, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "df['Bare Nuclei'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "677788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('?', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "030777d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "X = df.iloc[:, 0:8]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e84d9b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Benign:  458\n",
      "Number of Malignant :  241\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing target column\n",
    "ax = sns.countplot(y).set(title='Number of benign and malignant')\n",
    "B, M = y.value_counts()\n",
    "print('Number of Benign: ', B)\n",
    "print('Number of Malignant : ', M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c72e3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set scaler and classification model\n",
    "scaler = ['StandardScaler()', 'MinMaxScaler()', 'RobustScaler()', 'MaxAbsScaler()', 'Normalizer()']\n",
    "model = ['DecisionTreeClassifier(criterion=\"entropy\")', 'DecisionTreeClassifier(criterion=\"gini\")', 'LogisticRegression()']#, 'SVC(kernel=\"linear\", C=1e10)'\n",
    "\n",
    "def best_comb(scaler, model):\n",
    "    \"\"\"Train model and find best combination of classifier and scaler\n",
    "\n",
    "    Args:\n",
    "        scaler: Array of scaler you want to use\n",
    "        model: Array of classifier model you want to use\n",
    "\n",
    "    Returns:\n",
    "        combi: dictionary array including accuracy, scaler, classifier\n",
    "    \"\"\"\n",
    "    best_acc = 0\n",
    "    combi = [] #list element that stores the combination\n",
    "    for element in scaler:\n",
    "        scaler = eval(element)\n",
    "        scaled = scaler.fit_transform(X)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(scaled, y, test_size = 0.2, random_state=42) #Using random_state to fixing random rate\n",
    "        for element2 in model:\n",
    "            classifier = eval(element2)\n",
    "            classifier = classifier.fit(x_train,y_train)\n",
    "            \n",
    "            y_pred = classifier.predict(x_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            #print(f'Using {classifier} in {scaler} score : {acc}')\n",
    "            \n",
    "            combi.append({'acc' : acc, 'scaler' : element, 'classifier' : classifier})\n",
    "\n",
    "        \n",
    "    def get_acc(element): #function for getting accuracy in combi\n",
    "        return element['acc']\n",
    "    \n",
    "    #sort combination by accuracy, print 5 best combinations\n",
    "    combi.sort(key=get_acc, reverse=True)\n",
    "    \n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "    res = []\n",
    "    for i in range (0, 5):\n",
    "        res.append(cross_val_score(combi[i]['classifier'], X, y, cv = kfold))\n",
    "        temp = combi[i]\n",
    "        temp['kFold'] = 5\n",
    "        temp['acc'] = res[i].mean()\n",
    "        combi.append(temp)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "    res = []\n",
    "    for i in range (0, 5):\n",
    "        res.append(cross_val_score(combi[i]['classifier'], X, y, cv = kfold))\n",
    "        temp = combi[i]\n",
    "        temp['kFold'] = 10\n",
    "        temp['acc'] = res[i].mean()\n",
    "        combi.append(temp)\n",
    "    return combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c5f0aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combi = best_comb(scaler, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7cdd4a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 scaler, model, score in classificiation :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>scaler</th>\n",
       "      <th>classifier</th>\n",
       "      <th>kFold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.945631</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy')</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.871429</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.945631</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.961346</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.945631</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc            scaler                                   classifier  \\\n",
       "0   0.961346  StandardScaler()                         LogisticRegression()   \n",
       "1   0.961346    MinMaxScaler()                         LogisticRegression()   \n",
       "2   0.961346    RobustScaler()                         LogisticRegression()   \n",
       "3   0.961346    MaxAbsScaler()                         LogisticRegression()   \n",
       "4   0.945631    MinMaxScaler()                     DecisionTreeClassifier()   \n",
       "5   0.935714  StandardScaler()                     DecisionTreeClassifier()   \n",
       "6   0.935714    MinMaxScaler()  DecisionTreeClassifier(criterion='entropy')   \n",
       "7   0.935714    RobustScaler()  DecisionTreeClassifier(criterion='entropy')   \n",
       "8   0.935714    RobustScaler()                     DecisionTreeClassifier()   \n",
       "9   0.935714    MaxAbsScaler()  DecisionTreeClassifier(criterion='entropy')   \n",
       "10  0.935714    MaxAbsScaler()                     DecisionTreeClassifier()   \n",
       "11  0.928571  StandardScaler()  DecisionTreeClassifier(criterion='entropy')   \n",
       "12  0.900000      Normalizer()                     DecisionTreeClassifier()   \n",
       "13  0.892857      Normalizer()  DecisionTreeClassifier(criterion='entropy')   \n",
       "14  0.871429      Normalizer()                         LogisticRegression()   \n",
       "15  0.961346  StandardScaler()                         LogisticRegression()   \n",
       "16  0.961346    MinMaxScaler()                         LogisticRegression()   \n",
       "17  0.961346    RobustScaler()                         LogisticRegression()   \n",
       "18  0.961346    MaxAbsScaler()                         LogisticRegression()   \n",
       "19  0.945631    MinMaxScaler()                     DecisionTreeClassifier()   \n",
       "20  0.961346  StandardScaler()                         LogisticRegression()   \n",
       "21  0.961346    MinMaxScaler()                         LogisticRegression()   \n",
       "22  0.961346    RobustScaler()                         LogisticRegression()   \n",
       "23  0.961346    MaxAbsScaler()                         LogisticRegression()   \n",
       "24  0.945631    MinMaxScaler()                     DecisionTreeClassifier()   \n",
       "\n",
       "    kFold  \n",
       "0    10.0  \n",
       "1    10.0  \n",
       "2    10.0  \n",
       "3    10.0  \n",
       "4    10.0  \n",
       "5     NaN  \n",
       "6     NaN  \n",
       "7     NaN  \n",
       "8     NaN  \n",
       "9     NaN  \n",
       "10    NaN  \n",
       "11    NaN  \n",
       "12    NaN  \n",
       "13    NaN  \n",
       "14    NaN  \n",
       "15   10.0  \n",
       "16   10.0  \n",
       "17   10.0  \n",
       "18   10.0  \n",
       "19   10.0  \n",
       "20   10.0  \n",
       "21   10.0  \n",
       "22   10.0  \n",
       "23   10.0  \n",
       "24   10.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combi = pd.DataFrame (combi)\n",
    "print(f'Best 10 scaler, model, score in classificiation :', end='\\n\\n')\n",
    "df_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a2f65809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold validation with LogisticRegression(), StandardScaler() : [0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "Average in K-fold validation: 0.9642240493319629\n",
      "[0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "\n",
      "K-fold validation with LogisticRegression(), MinMaxScaler() : [0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "Average in K-fold validation: 0.9642240493319629\n",
      "[0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "\n",
      "K-fold validation with LogisticRegression(), RobustScaler() : [0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "Average in K-fold validation: 0.9642240493319629\n",
      "[0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "\n",
      "K-fold validation with LogisticRegression(), MaxAbsScaler() : [0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "Average in K-fold validation: 0.9642240493319629\n",
      "[0.95714286 0.92857143 0.98571429 0.99285714 0.95683453]\n",
      "\n",
      "K-fold validation with DecisionTreeClassifier(), MinMaxScaler() : [0.93571429 0.91428571 0.95714286 0.96428571 0.92086331]\n",
      "Average in K-fold validation: 0.938458376156218\n",
      "[0.93571429 0.91428571 0.95714286 0.96428571 0.92086331]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def val(combi, X, y):\n",
    "    \"\"\"Validation model with k-fold validation\n",
    "\n",
    "    Args:\n",
    "        scaler: Array of accuracy score, scaler and model\n",
    "        X: Array of attributes except target attribute\n",
    "        y: Array of target attribute\n",
    "\n",
    "    Returns:\n",
    "        best_acc: return best accuracy among combination of scaler and model\n",
    "        best_scaler: return scaler which has best score\n",
    "        best_model: return model which has best score\n",
    "    \"\"\"\n",
    "res = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "for i in range (0, 5):\n",
    "    res.append(cross_val_score(combi[i]['classifier'], X, y, cv = kfold))\n",
    "    print(f\"K-fold validation with {combi[i]['classifier']}, {combi[i]['scaler']} : {res[i]}\")\n",
    "    print(f\"Average in K-fold validation: {res[i].mean()}\")\n",
    "    print(res[i], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256ce9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b91a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
